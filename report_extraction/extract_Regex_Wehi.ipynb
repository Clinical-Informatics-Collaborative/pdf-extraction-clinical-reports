{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4861c43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\users\\rosa0\\anaconda3\\lib\\site-packages (1.22.2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import fitz\n",
    "c=\"data0\"\n",
    "a= \"generatedWehi\"\n",
    "b= \"18465975MDXN[20]\"\n",
    "fname = a\n",
    "# Open the PDF file\n",
    "doc = fitz.open(fname+\".pdf\")\n",
    "\n",
    "# Iterate through the pages of the PDF and extract the text\n",
    "out = open(fname + \".txt\", \"wb\")\n",
    "for page in doc:\n",
    "    text = page.get_text().encode(\"utf8\")\n",
    "    out.write(text)\n",
    "\n",
    "doc.close()\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d74ee317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Nell Cox', 'Lab No': '17999458', 'Ext Ref': '1745766441', 'Collected': '04-Jun-2022', 'Received': '04-Oct-2023', 'Specimen': 'Muscle biopsy test', 'Requester': 'DrJoan Lewis', 'Referral Lab': 'Dorevitch Pathology', 'URN': 'PMEX347746', 'DOB': '04-Dec-1994', 'Sex': 'M'}\n"
     ]
    }
   ],
   "source": [
    "#change the regex pattern so it can match the new format\n",
    "import re\n",
    "\n",
    "def extract_patient_info(text):\n",
    "    patient_info = {}\n",
    "    \n",
    "    keyword1 = [\"Name\",\"Lab No\",\"Ext Ref\",\"Collected\",\"Received\",\"Ext Ref\",\"Specimen\",\"Requester\",\"Referral Lab\"]\n",
    "    keyword2 = [\"URN\",\"DOB\",\"Sex\"]\n",
    "    for w in keyword1:\n",
    "        match = re.search(f\"(?<={w}:\\s)[^\\n]*\\S\", text)\n",
    "        if match:\n",
    "            patient_info[w] = match.group().strip()\n",
    "        else:\n",
    "            patient_info[w] = \"\"\n",
    "    for w in keyword2:\n",
    "        match = re.search(f\"{w}:\\s+([^\\n]+)\", text)\n",
    "        if match:\n",
    "            patient_info[w] = match.group(1).strip()\n",
    "        else:\n",
    "            patient_info[w] = \"\"       \n",
    "#     for w in keyword2:\n",
    "#         match = re.search(f\"{w}\\s+([^\\n]+)\", text).group(1).strip()\n",
    "#         if match:\n",
    "#             patient_info[w] = match\n",
    "#         else:\n",
    "#             patient_info[w] = \"\"\n",
    "    return patient_info\n",
    "\n",
    "with open(fname + \".txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    patient_info = extract_patient_info(text)\n",
    "    print(patient_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2878df5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[{'ASSUMED ORIGIN': 'Somatic', 'GENE': 'FLT3', 'VARIANT': 'FLT3-ITD (allelicratio 0.76)', 'VRF (%)': '14', 'CLINICAL SIGNIFICANCE IN AML': 'DIAGNOSTIC'}, {'ASSUMED ORIGIN': 'Eukaryotic', 'GENE': 'ALDH2', 'VARIANT': 'c.2842del,p.(Glu948Argfs*3)', 'VRF (%)': '11', 'CLINICAL SIGNIFICANCE IN AML': 'PROGNOSTIC / DRUG TARGET'}, {'ASSUMED ORIGIN': 'Prokaryotic', 'GENE': 'CFTR', 'VARIANT': 'c.2645G>A,p.(Arg882His)', 'VRF (%)': '11', 'CLINICAL SIGNIFICANCE IN AML': 'CLONAL MARKER'}]\n"
     ]
    }
   ],
   "source": [
    "#remove the extra \",\" when extracting \"VARIANT\" field\n",
    "def extract_variants(text):\n",
    "    num =0 #number of variants recorded in teh report\n",
    "    result = []\n",
    "    #remove irrelecant sections and the (%)\n",
    "    match = re.search(r\"(ASSUMED ORIGIN.*VRF – variant read frequency)\", text, flags=re.DOTALL)\n",
    "    preprocess = match.group(1)\n",
    "    preprocess = re.sub(r\"\\n\\(%\\)\", \"\", preprocess)\n",
    "    preprocess = re.sub(\"VRF – variant read frequency\", \"\", preprocess)\n",
    "    \n",
    "    \n",
    "    # Split the preprocessed text by lines and remove empty lines\n",
    "    lines = [line.strip() for line in preprocess.split('\\n') if line.strip()]    \n",
    "    \n",
    "    #split the headers and table contents\n",
    "    header = lines[:5]\n",
    "    lines = lines[5:]\n",
    "    \n",
    "    #in some circanstances, viriants may be split to two lines. join the two lines\n",
    "    pattern_VARIANT = r\"^(c|p)\\.[A-Za-z0-9()>*=]+\"\n",
    "    i = 0\n",
    "    while (i<len(lines)):\n",
    "        match = re.match(pattern_VARIANT,lines[i])\n",
    "        if match:\n",
    "            temp = lines.pop(i+1)\n",
    "            lines[i] = lines[i] + temp\n",
    "        i+=1\n",
    "        \n",
    "    pattern_bracket = r\".*\\([a-zA-Z]+$\"\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        match = re.match(pattern_bracket,lines[i])\n",
    "        if match:\n",
    "            temp = lines.pop(i+1)\n",
    "            lines[i] = lines[i] + temp\n",
    "        i+=1\n",
    "\n",
    "    #put result into a dictionary\n",
    "    j = 0\n",
    "    while (j<len(lines)):\n",
    "        dic = {}\n",
    "        dic[header[0]] = lines[j]\n",
    "        dic[header[1]] = lines[j+1]\n",
    "        dic[header[2]] = lines[j+2]\n",
    "        dic[header[3]] = lines[j+3]\n",
    "        dic[header[4]] = lines[j+4]\n",
    "        result.append(dic)\n",
    "        j = j+5\n",
    "    return result\n",
    "\n",
    "with open(fname + \".txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    a = extract_variants(text)\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee4db975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "with open(fname + \".txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    patient_info = extract_patient_info(text)\n",
    "    reportable_variants = extract_variants(text)\n",
    "    \n",
    "    dic = {\"patient_info\":patient_info, \"reportable_variants\":reportable_variants }\n",
    "    result = json.dumps(dic, indent = 3)\n",
    "    \n",
    "    jsonFile = open(fname+\".json\", \"w\")\n",
    "    jsonFile.write(result)\n",
    "    jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b797a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the txt\n",
    "import os\n",
    "os.remove(fname+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56857ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3343e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
